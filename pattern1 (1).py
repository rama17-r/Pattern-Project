# -*- coding: utf-8 -*-
"""Pattern1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JlkpIKubRt-Gjc1Xe_6eHrKnCKYE2Ada

# Mount Google Drive (optional if you store datasets there)
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Install required libraries"""

!pip install geopandas shapely geemap earthengine-api

"""# Import necessary libraries"""

import pandas as pd
import numpy as np

from google.colab import files

from shapely import wkt
from shapely.geometry import shape
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""#Data Loading and Preprocessing"""

train_data = pd.read_csv('/content/Train (1).csv')
test_data = pd.read_csv('/content/Test (1).csv')

print("Train Data Head:")
print(train_data.head())

"""#Check for missing values in data"""

print("\nMissing Values in Training Data:")
print(train_data.isnull().sum())

"""# Convert time columns"""

train_data['SDate'] = pd.to_datetime(train_data['SDate'], errors='coerce')
train_data['HDate'] = pd.to_datetime(train_data['HDate'], errors='coerce')

print("\nProcessed Date Columns:")
print(train_data[['SDate', 'HDate']].head())

"""# Extract date properties"""

train_data['CropDuration'] = (train_data['HDate'] - train_data['SDate']).dt.days
print("Crop Duration Added:")
train_data['CropDuration'].head()

train_data = train_data.drop(columns=['SDate', 'HDate'])

print("Updated Training Data:")
print(train_data.head())

"""# Encode text data into numbers"""

categorical_columns = ['Crop', 'IrriType', 'Season', 'State', 'District',
                       'Sub-District', 'CNext', 'CLast', 'CTransp', 'IrriSource']
for col in categorical_columns:
    train_data[col] = train_data[col].astype('category').cat.codes

"""# Display the converted columns to preview the new values"""

for col in categorical_columns:
    print(f"Unique values in '{col}' after encoding:")
    print(train_data[col].unique())
    print("-" * 50)

"""# Convert texts in a geometry column into geometric objects"""

train_data['geometry'] = train_data['geometry'].apply(wkt.loads)

# Extract geometric properties
train_data['Area'] = train_data['geometry'].apply(lambda x: x.area)
train_data['Perimeter'] = train_data['geometry'].apply(lambda x: x.length)
train_data['Centroid_X'] = train_data['geometry'].apply(lambda x: x.centroid.x)
train_data['Centroid_Y'] = train_data['geometry'].apply(lambda x: x.centroid.y)

# Delete original column 'geometry'
train_data = train_data.drop(columns=['geometry'])

print(train_data.head())

"""#Testing Data"""

# تحويل 'geometry' إلى كائن هندسي
test_data['geometry'] = test_data['geometry'].apply(wkt.loads)

# استخراج الخصائص الهندسية
test_data['Area'] = test_data['geometry'].apply(lambda x: x.area)
test_data['Perimeter'] = test_data['geometry'].apply(lambda x: x.length)
test_data['Centroid_X'] = test_data['geometry'].apply(lambda x: x.centroid.x)
test_data['Centroid_Y'] = test_data['geometry'].apply(lambda x: x.centroid.y)

# حذف العمود الأصلي 'geometry'
test_data = test_data.drop(columns=['geometry'])

# عرض البيانات للتحقق
print(test_data.head())

categorical_columns = ['Crop', 'IrriType', 'Season', 'State', 'District',
                       'Sub-District', 'CNext', 'CLast', 'CTransp', 'IrriSource']

for col in categorical_columns:
    train_data[col] = train_data[col].astype('category').cat.codes

print(train_data[categorical_columns].head())

categorical_columns = ['Crop', 'IrriType', 'Season', 'State', 'District',
                       'Sub-District', 'CNext', 'CLast', 'CTransp', 'IrriSource']

# Apply markup to test_data in the same way as it was applied to train_data
for col in categorical_columns:
    test_data[col] = test_data[col].astype('category').cat.codes

print(test_data[categorical_columns].head())

"""# Divide training data into Training and Validation

"""

X = train_data.drop(columns=['category'])
y = train_data['category']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
print("\nTraining and Validation Data Split Completed.")

#first 5 rows of training data
print("Training Data (X_train):")
print(X_train.head())
print("\nTarget Data (y_train):")
print(y_train.head())

#first 5 rows of verification data
print("\nValidation Data (X_val):")
print(X_val.head())
print("\nTarget Data (y_val):")
print(y_val.head())

print("Shape of X_train:", X_train.shape)
print("Shape of X_val:", X_val.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_val:", y_val.shape)

# Arrange the columns in test_data to match the order of the columns in X_train
test_data = test_data[X_train.columns]

# Display data to check column order
print("Test Data After Matching Columns:")
print(test_data.head())

# Order the columns in test_data to match the order of the columns in X_train
test_data = test_data[X.columns]

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Prediction on verification data
y_pred = model.predict(X_val)

"""# Evaluate the model"""

accuracy = accuracy_score(y_val, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

print("Classification Report:")
print(classification_report(y_val, y_pred))

print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

"""# Prediction on test data

"""

test_predictions = model.predict(test_data)
print("Test Predictions:")
print(test_predictions)

# توزيع الفئات في بيانات التدريب
print("Training Data Class Distribution:")
print(y.value_counts())

from sklearn.metrics import f1_score

# حساب F1-Score على بيانات التحقق
f1 = f1_score(y_val, y_pred, average='weighted')
print(f"F1-Score: {f1:.2f}")

test_predictions = model.predict(test_data)
print("Test Predictions:")
print(test_predictions)

from imblearn.over_sampling import SMOTE

# Apply SMOTE to training data
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Check the distribution of classes after SMOTE
print(pd.Series(y_resampled).value_counts())

test_predictions = model.predict(test_data)
print("Test Predictions:")
print(test_predictions)

